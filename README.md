# AI MLOps Project

&#x20;     &#x20;

---

## âœ¨ Latest Updates (June 2025)

- âœ… Advanced time-based feature engineering (Spark-driven)
- âœ… `train_sklearn.py`: Calibrated + threshold-optimized RandomForest
- âœ… `train_spark.py`: Distributed GBTClassifier + full evaluation
- âœ… Precision and F1 improvements through GridSearch and calibration
- âœ… MLflow artifact tracking fully structured and consistent
- âœ… YAML-driven hyperparameter config with rolling metric logs
- âœ… Added model signature, input examples, confusion matrices, ROC, PR curves
- âœ… CI/CD improved with Buildx caching, protected branches, and PAT for semantic-release
- âœ… Docker build hardened with retry logic and compressed layer caching
- âœ… Multiple PR templates + branch rules enforced in GitHub Actions
- âœ… OpenAI-powered LLM reporting integrated into CI pipeline

---

## ğŸ” Project Overview

AI MLOps Platform for **behavioral purchase prediction**, equipped with:

- ğŸšš Data ingestion (local + AWS S3)
- ğŸ”€ Spark-based feature engineering (time, recency, behavioral signals)
- âš–ï¸ Class imbalance handling (SMOTETomek, dynamic class weights)
- ğŸ§  Dual model engines: Scikit-learn (dev) & Spark MLlib (prod)
- ğŸ” GridSearch & CrossValidator support
- ğŸ“ˆ MLflow experiment tracking + threshold-based metrics
- ğŸ“¦ Docker-ready + CI/CD (GitHub Actions)
- ğŸ¤– OpenAI API integration for automated AI reporting, with dynamic prompts and structured analysis of model results and business KPIs.

---

## ğŸ“ƒ Semantic Release

- Uses `@semantic-release` to automatically version and tag builds from main
- Integrated PAT token to bypass protection rules
- Full changelog and release notes updated via plugin

Command for dry-run:

```bash
npx semantic-release --dry-run
```

---

## ğŸ”¢ GitHub Workflows Summary

Main CI/CD file: `.github/workflows/ci-cd.yml`

Includes jobs:

- `build-and-test`: local lint, test, train
- `docker-build-and-push`: buildx + GHCR
- `model-smoke-test`: simple inference test
- `semantic-release`: versioning and release

Protected branches supported via PAT: `secrets.PAT_GITHUB`

---

## ğŸ”¹ Run Full Project (DEV & PROD)

```bash
# Create and activate environment
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# DEVELOPMENT
make ingest-dev-local
make process-dev-local
make train-dev-local
make test-dev

# PRODUCTION
make ingest-prod-local
make process-prod-local
make train-prod-local
make test-prod

# Launch MLflow UI
make mlflow-local
```

---

## ğŸ”¢ Model Pipelines

| Mode | Engine       | Pipeline Summary                                 |
| ---- | ------------ | ------------------------------------------------ |
| dev  | Scikit-learn | SMOTETomek + RF + Calibration + GridSearchCV     |
| prod | Spark MLlib  | GBTClassifier + VectorAssembler + CrossValidator |

Dispatcher:

```bash
python models/train.py --env dev
python models/train.py --env prod
```

---

## ğŸ—ï¸ Project Structure

```bash
ai-mlops-project/
â”œâ”€â”€ configs/           # Environment YAMLs, training parameters, MLflow config
â”œâ”€â”€ data/              # Datasets (raw, intermediate, processed) 
â”œâ”€â”€ data_ingestion/    # Scripts for data download, loading, and storage
â”œâ”€â”€ data_processing/   # Spark-based feature engineering and preprocessing pipelines
â”œâ”€â”€ docs/              # Markdown documentation, diagrams, architecture notes
â”œâ”€â”€ generative_ai/     # LLM integrations, prompts, embedding pipelines, NLP tools
â”œâ”€â”€ mlruns/            # MLflow experiment logs and artifacts (auto-generated)
â”œâ”€â”€ models/            # Sklearn & Spark training pipelines, model classes, training logic
â”œâ”€â”€ scripts/           # CLI scripts for training, evaluation, deployment
â”œâ”€â”€ tests/             # Pytest-based unit and integration tests
â”œâ”€â”€ Makefile           # Full pipeline automation: make train, make deploy, make test, etc.
â””â”€â”€ .github/           # CI/CD workflows, CODEOWNERS, and GitHub Actions
```

---

## ğŸš€ Quickstart

```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

make train-dev-local   # Local sklearn pipeline
make train-prod-local  # Distributed Spark training
make mlflow-local      # MLflow UI
```

---

## ğŸ“˜ï¸ Documentation

- ğŸ“Š [Data Processing](./docs/data_processing.md)
- ğŸ”§ [Model Training](./docs/models.md)
- ğŸ“¦ [MLflow Registry](./docs/mlflow_registry.md)
- ğŸ“¦ [Dependencies](./docs/dependencies.md)
- ğŸ“¦ [Github Workflow](./docs/github-workflow.md)
- ğŸ“¦ [Semantic Commit](./docs/semantic-commit-guide.md)
- ğŸ“¦ [Makefile](./Makefile)

---

## ğŸ”„ CI/CD Pipeline

- ğŸ§ª Unit tests and validations (local + Docker-based)
- ğŸ“¦ Model artifact verification
- ğŸ”€ MLflow logging consistency checks
- ğŸ³ Docker image with Buildx caching
- ğŸŒ Semantic Release with PAT (protected branch support)
- ğŸ“Œ PR Templates and branch rules enforced
- ğŸ¤– OpenAI-integrated reporting (Generative AI)

---

## ğŸ”® Roadmap

- â³ Optuna optimization support
- â˜ï¸ Cloud deployment (EMR, SageMaker)
- ğŸŒ MLflow + FastAPI model serving
- ğŸ¤– LLM-powered monitoring

---

**Maintainer:** Erick Jara â€” CTO & AI/Data Engineer\
ğŸ“§ [erick.jara@hotmail.it](mailto\:erick.jara@hotmail.it) | ğŸŒ GitHub: [Impesud](https://github.com/Impesud)





